{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e94dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbc9dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the words\n",
    "words = open('/Users/rajesh/Documents/Datasets/names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d68434b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a991470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# Build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cd9c06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... -----> e\n",
      "..e -----> m\n",
      ".em -----> m\n",
      "emm -----> a\n",
      "mma -----> .\n",
      "olivia\n",
      "... -----> o\n",
      "..o -----> l\n",
      ".ol -----> i\n",
      "oli -----> v\n",
      "liv -----> i\n",
      "ivi -----> a\n",
      "via -----> .\n",
      "ava\n",
      "... -----> a\n",
      "..a -----> v\n",
      ".av -----> a\n",
      "ava -----> .\n",
      "isabella\n",
      "... -----> i\n",
      "..i -----> s\n",
      ".is -----> a\n",
      "isa -----> b\n",
      "sab -----> e\n",
      "abe -----> l\n",
      "bel -----> l\n",
      "ell -----> a\n",
      "lla -----> .\n",
      "sophia\n",
      "... -----> s\n",
      "..s -----> o\n",
      ".so -----> p\n",
      "sop -----> h\n",
      "oph -----> i\n",
      "phi -----> a\n",
      "hia -----> .\n"
     ]
    }
   ],
   "source": [
    "# Build the dataset\n",
    "\n",
    "block_size = 3     # Context Length: How many previous characters do we use to predict the next one?\n",
    "X, Y = [], []\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        idx = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(idx)\n",
    "        print(''.join(itos[i] for i in context), '----->', itos[idx])\n",
    "        context = context[1:] + [idx]     # Crop and append\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80f31812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb27982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding logup table\n",
    "C = torch.randn((27,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "651361d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5771, -0.2291])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fa63641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f152e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5771, -0.2291])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply the one hot encoding vector with the columns of C\n",
    "\n",
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "311147bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5771, -0.2291],\n",
       "        [-0.3132, -1.0164],\n",
       "        [-0.2915,  1.8365],\n",
       "        [-0.2915,  1.8365],\n",
       "        [-0.2915,  1.8365],\n",
       "        [-0.2915,  1.8365]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get multiple elements\n",
    "# Note that the index 7 is repeated multiple times and will be retrieved as many times\n",
    "C[torch.tensor([5,6,7,7,7,7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c85b31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f8aa801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using pytorch indexing we create our embedding as follows\n",
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7324a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the hidden layer\n",
    "# We have 3 embeddings each of which is 2 dimensional - 6 inputs\n",
    "# Assume 100 neurons in the hidden layer\n",
    "# b is bias\n",
    "\n",
    "W1 = torch.randn((6,100))\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5c0a050",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (96x2 and 6x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# We want to multiply the embeddings by the weight\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43memb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW1\u001b[49m \u001b[38;5;241m+\u001b[39m b1\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (96x2 and 6x100)"
     ]
    }
   ],
   "source": [
    "# We want to multiply the embeddings by the weight\n",
    "# However, the below gives an error because the embeddings have not been concatenated\n",
    "emb @ W1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec01fe6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1960, -1.3210,  1.1960, -1.3210,  1.1960, -1.3210],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210, -0.5771, -0.2291],\n",
       "        [ 1.1960, -1.3210, -0.5771, -0.2291,  1.2075, -0.6821],\n",
       "        [-0.5771, -0.2291,  1.2075, -0.6821,  1.2075, -0.6821],\n",
       "        [ 1.2075, -0.6821,  1.2075, -0.6821,  0.6793, -1.3878],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210,  1.1960, -1.3210],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210, -1.2841,  1.7233],\n",
       "        [ 1.1960, -1.3210, -1.2841,  1.7233,  2.0226, -1.2506],\n",
       "        [-1.2841,  1.7233,  2.0226, -1.2506,  1.1542,  0.4299],\n",
       "        [ 2.0226, -1.2506,  1.1542,  0.4299, -0.5908,  0.8096],\n",
       "        [ 1.1542,  0.4299, -0.5908,  0.8096,  1.1542,  0.4299],\n",
       "        [-0.5908,  0.8096,  1.1542,  0.4299,  0.6793, -1.3878],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210,  1.1960, -1.3210],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210,  0.6793, -1.3878],\n",
       "        [ 1.1960, -1.3210,  0.6793, -1.3878, -0.5908,  0.8096],\n",
       "        [ 0.6793, -1.3878, -0.5908,  0.8096,  0.6793, -1.3878],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210,  1.1960, -1.3210],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210,  1.1542,  0.4299],\n",
       "        [ 1.1960, -1.3210,  1.1542,  0.4299, -0.6814, -0.0943],\n",
       "        [ 1.1542,  0.4299, -0.6814, -0.0943,  0.6793, -1.3878],\n",
       "        [-0.6814, -0.0943,  0.6793, -1.3878, -0.6247,  1.1240],\n",
       "        [ 0.6793, -1.3878, -0.6247,  1.1240, -0.5771, -0.2291],\n",
       "        [-0.6247,  1.1240, -0.5771, -0.2291,  2.0226, -1.2506],\n",
       "        [-0.5771, -0.2291,  2.0226, -1.2506,  2.0226, -1.2506],\n",
       "        [ 2.0226, -1.2506,  2.0226, -1.2506,  0.6793, -1.3878],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210,  1.1960, -1.3210],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210, -0.6814, -0.0943],\n",
       "        [ 1.1960, -1.3210, -0.6814, -0.0943, -1.2841,  1.7233],\n",
       "        [-0.6814, -0.0943, -1.2841,  1.7233,  0.6852, -2.2540],\n",
       "        [-1.2841,  1.7233,  0.6852, -2.2540, -0.2732,  0.7326],\n",
       "        [ 0.6852, -2.2540, -0.2732,  0.7326,  1.1542,  0.4299],\n",
       "        [-0.2732,  0.7326,  1.1542,  0.4299,  0.6793, -1.3878]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the emb is a tensor of size 32, 3, 2\n",
    "# This results in a 32 x 6 tensor by concatenating the 3 embeddings\n",
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb [:, 2, :]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36555214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.1960, -1.3210],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [-0.5771, -0.2291],\n",
       "         [ 1.2075, -0.6821],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [-1.2841,  1.7233],\n",
       "         [ 2.0226, -1.2506],\n",
       "         [ 1.1542,  0.4299],\n",
       "         [-0.5908,  0.8096],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 0.6793, -1.3878],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1542,  0.4299],\n",
       "         [-0.6814, -0.0943],\n",
       "         [ 0.6793, -1.3878],\n",
       "         [-0.6247,  1.1240],\n",
       "         [-0.5771, -0.2291],\n",
       "         [ 2.0226, -1.2506],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [-0.6814, -0.0943],\n",
       "         [-1.2841,  1.7233],\n",
       "         [ 0.6852, -2.2540],\n",
       "         [-0.2732,  0.7326]]),\n",
       " tensor([[ 1.1960, -1.3210],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [-0.5771, -0.2291],\n",
       "         [ 1.2075, -0.6821],\n",
       "         [ 1.2075, -0.6821],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [-1.2841,  1.7233],\n",
       "         [ 2.0226, -1.2506],\n",
       "         [ 1.1542,  0.4299],\n",
       "         [-0.5908,  0.8096],\n",
       "         [ 1.1542,  0.4299],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 0.6793, -1.3878],\n",
       "         [-0.5908,  0.8096],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1542,  0.4299],\n",
       "         [-0.6814, -0.0943],\n",
       "         [ 0.6793, -1.3878],\n",
       "         [-0.6247,  1.1240],\n",
       "         [-0.5771, -0.2291],\n",
       "         [ 2.0226, -1.2506],\n",
       "         [ 2.0226, -1.2506],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [-0.6814, -0.0943],\n",
       "         [-1.2841,  1.7233],\n",
       "         [ 0.6852, -2.2540],\n",
       "         [-0.2732,  0.7326],\n",
       "         [ 1.1542,  0.4299]]),\n",
       " tensor([[ 1.1960, -1.3210],\n",
       "         [-0.5771, -0.2291],\n",
       "         [ 1.2075, -0.6821],\n",
       "         [ 1.2075, -0.6821],\n",
       "         [ 0.6793, -1.3878],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [-1.2841,  1.7233],\n",
       "         [ 2.0226, -1.2506],\n",
       "         [ 1.1542,  0.4299],\n",
       "         [-0.5908,  0.8096],\n",
       "         [ 1.1542,  0.4299],\n",
       "         [ 0.6793, -1.3878],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 0.6793, -1.3878],\n",
       "         [-0.5908,  0.8096],\n",
       "         [ 0.6793, -1.3878],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [ 1.1542,  0.4299],\n",
       "         [-0.6814, -0.0943],\n",
       "         [ 0.6793, -1.3878],\n",
       "         [-0.6247,  1.1240],\n",
       "         [-0.5771, -0.2291],\n",
       "         [ 2.0226, -1.2506],\n",
       "         [ 2.0226, -1.2506],\n",
       "         [ 0.6793, -1.3878],\n",
       "         [ 1.1960, -1.3210],\n",
       "         [-0.6814, -0.0943],\n",
       "         [-1.2841,  1.7233],\n",
       "         [ 0.6852, -2.2540],\n",
       "         [-0.2732,  0.7326],\n",
       "         [ 1.1542,  0.4299],\n",
       "         [ 0.6793, -1.3878]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.unbind to remove a tensor dimension\n",
    "torch.unbind(emb, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b10d838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the Pytorch concatenation creates a whole new tensor that uses new memory\n",
    "\n",
    "torch.cat(torch.unbind(emb, 1), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7464a676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch views are more efficient ways of concatenating the data\n",
    "a = torch.arange(18)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12e6be5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12, 13, 14, 15, 16, 17]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The above torch vector can be represented as different sized tensors\n",
    "a.view(2,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28a210a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(3,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c152793c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       "[torch.storage._TypedStorage(dtype=torch.int64, device=cpu) of size 18]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storage is always a 1-D vector in memory\n",
    "a.storage()\n",
    "\n",
    "# Reference: log.ezyang.com (PyTorch internals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17cda81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9615e44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1960, -1.3210,  1.1960, -1.3210,  1.1960, -1.3210],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210, -0.5771, -0.2291],\n",
       "        [ 1.1960, -1.3210, -0.5771, -0.2291,  1.2075, -0.6821],\n",
       "        [-0.5771, -0.2291,  1.2075, -0.6821,  1.2075, -0.6821],\n",
       "        [ 1.2075, -0.6821,  1.2075, -0.6821,  0.6793, -1.3878],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210,  1.1960, -1.3210],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210, -1.2841,  1.7233],\n",
       "        [ 1.1960, -1.3210, -1.2841,  1.7233,  2.0226, -1.2506],\n",
       "        [-1.2841,  1.7233,  2.0226, -1.2506,  1.1542,  0.4299],\n",
       "        [ 2.0226, -1.2506,  1.1542,  0.4299, -0.5908,  0.8096],\n",
       "        [ 1.1542,  0.4299, -0.5908,  0.8096,  1.1542,  0.4299],\n",
       "        [-0.5908,  0.8096,  1.1542,  0.4299,  0.6793, -1.3878],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210,  1.1960, -1.3210],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210,  0.6793, -1.3878],\n",
       "        [ 1.1960, -1.3210,  0.6793, -1.3878, -0.5908,  0.8096],\n",
       "        [ 0.6793, -1.3878, -0.5908,  0.8096,  0.6793, -1.3878],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210,  1.1960, -1.3210],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210,  1.1542,  0.4299],\n",
       "        [ 1.1960, -1.3210,  1.1542,  0.4299, -0.6814, -0.0943],\n",
       "        [ 1.1542,  0.4299, -0.6814, -0.0943,  0.6793, -1.3878],\n",
       "        [-0.6814, -0.0943,  0.6793, -1.3878, -0.6247,  1.1240],\n",
       "        [ 0.6793, -1.3878, -0.6247,  1.1240, -0.5771, -0.2291],\n",
       "        [-0.6247,  1.1240, -0.5771, -0.2291,  2.0226, -1.2506],\n",
       "        [-0.5771, -0.2291,  2.0226, -1.2506,  2.0226, -1.2506],\n",
       "        [ 2.0226, -1.2506,  2.0226, -1.2506,  0.6793, -1.3878],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210,  1.1960, -1.3210],\n",
       "        [ 1.1960, -1.3210,  1.1960, -1.3210, -0.6814, -0.0943],\n",
       "        [ 1.1960, -1.3210, -0.6814, -0.0943, -1.2841,  1.7233],\n",
       "        [-0.6814, -0.0943, -1.2841,  1.7233,  0.6852, -2.2540],\n",
       "        [-1.2841,  1.7233,  0.6852, -2.2540, -0.2732,  0.7326],\n",
       "        [ 0.6852, -2.2540, -0.2732,  0.7326,  1.1542,  0.4299],\n",
       "        [-0.2732,  0.7326,  1.1542,  0.4299,  0.6793, -1.3878]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db4effa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elementwise equality comparison\n",
    "emb.view(32,6) == torch.cat(torch.unbind(emb, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98d8f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back to the hidden layer\n",
    "\n",
    "# Note that the -1 is interpreted by Pytorch as the remaining number of elements\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "\n",
    "# Note that + b1 is using broadcasting.\n",
    "# (emb.view(-1, 6) @ W1).shape = torch.Size([32,100])\n",
    "# b1.shape = torch.Size([100])\n",
    "# Broadcasting will align from the right and create a fake dimension (32)\n",
    "# 32, 100\n",
    "# 1, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "784b4ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8824, -0.9436, -0.9902,  ...,  0.9998, -0.8671,  0.5502],\n",
       "        [-0.9745,  0.4683,  0.3501,  ...,  0.7964,  0.8828,  0.9975],\n",
       "        [-0.8380, -0.2689, -0.9956,  ...,  0.9753, -0.9988, -0.9362],\n",
       "        ...,\n",
       "        [ 0.9512, -0.9699, -0.8260,  ..., -0.9998,  0.9580, -0.0167],\n",
       "        [-0.9100,  0.3560,  0.0192,  ..., -0.0477, -0.9796, -0.3332],\n",
       "        [-0.1659, -0.4239, -0.5958,  ...,  0.9731,  0.3468, -0.8914]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8a5c083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hidden layer activations for every one of our 32 examples\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7af2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output layer\n",
    "W2 = torch.randn((100,27))\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e06e1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "364169c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "523e275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e266d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = counts / counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7de589ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a677aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b008e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9456edba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.4865e-07, 1.7293e-09, 3.2944e-06, 9.5399e-09, 5.5139e-09, 5.5676e-10,\n",
       "        1.1106e-12, 5.9247e-07, 6.0100e-07, 6.0706e-12, 7.5055e-05, 4.4485e-10,\n",
       "        1.6402e-09, 5.9678e-15, 1.0081e-12, 7.4332e-17, 1.3846e-14, 7.3601e-12,\n",
       "        6.1881e-15, 1.5773e-09, 3.3201e-10, 1.5053e-03, 1.9106e-04, 8.6259e-09,\n",
       "        3.7251e-09, 2.4509e-08, 3.5941e-15, 9.7709e-01, 1.3646e-03, 1.5575e-06,\n",
       "        6.8454e-10, 1.1420e-08])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the probabilities of the expected output (Y)\n",
    "prob[torch.arange(32), Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b61bcfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19.7612)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf557f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62094bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d91a91cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27,2), generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100,27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8eb95f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # Total number of parameters in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74d680d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7697)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X] #(32, 3,2)\n",
    "h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdims=True)\n",
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bdb9b35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7697)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The loss calculation is encapsulated in the Functional.cross_entropy function\n",
    "# We get the exact same loss as above\n",
    "F.cross_entropy(logits,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "892d9f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.0466e-04, 3.3281e-04, 6.6846e-03, 9.9208e-01])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F.cross_entropy is more computationally efficient as it doesn't create new intermediate tensors\n",
    "# F.cross_entropy is numerically well behaved.\n",
    "logits = torch.tensor([-2, -3, 0, 5])\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum()\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff475a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., nan])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Large positive numbers can result in out of range (or NaN)\n",
    "logits = torch.tensor([-100, -3, 0, 100])\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum()\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce1925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy calculation subtracts the largest positive number to keep the numeric calculation well behaved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "287ea5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5079e-05, 3.3309e-04, 6.6903e-03, 9.9293e-01])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.tensor([-5, -3, 0, 5])\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum()\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d26a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the largest positive number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fdc6dfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5079e-05, 3.3309e-04, 6.6903e-03, 9.9293e-01])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The result is the same\n",
    "logits = torch.tensor([-5, -3, 0, 5]) - 5\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum()\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7387a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "859221a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25560152530670166\n"
     ]
    }
   ],
   "source": [
    "# Set up training of the neural network\n",
    "# Learning rate eta\n",
    "eta = 0.1\n",
    "\n",
    "for _ in range(100):\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X] #(32, 3,2)\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    # print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # Parameter update\n",
    "    for p in parameters:\n",
    "        p.data += -eta * p.grad\n",
    "\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "48ce8750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([13.4138, 17.9647, 20.6772, 20.7265, 16.8572, 13.4138, 16.1148, 14.2719,\n",
       "        16.0143, 18.5009, 16.0740, 21.0530, 13.4138, 17.2576, 17.2659, 20.2015,\n",
       "        13.4138, 16.7051, 15.2578, 17.2019, 18.6944, 16.1059, 10.9961, 10.7945,\n",
       "        15.5882, 13.4138, 16.2896, 17.0883, 12.8242, 16.2912, 19.2261, 16.1884],\n",
       "       grad_fn=<MaxBackward0>),\n",
       "indices=tensor([19, 13, 13,  1,  0, 19, 12,  9, 22,  9,  1,  0, 19, 22,  1,  0, 19, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the max of logits along the first dimension\n",
    "# Pytorch prints the max values and also the indices that can be compared with Y\n",
    "logits.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ebe4962e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "65a580b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the full data set and optimize the neural network\n",
    "\n",
    "# Build the dataset\n",
    "\n",
    "block_size = 3     # Context Length: How many previous characters do we use to predict the next one?\n",
    "X, Y = [], []\n",
    "for w in words:\n",
    "    # print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        idx = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(idx)\n",
    "        # print(''.join(itos[i] for i in context), '----->', itos[idx])\n",
    "        context = context[1:] + [idx]     # Crop and append\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f814d4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e7365777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize the network\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27,2), generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100,27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f9f2dea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d44d9ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "79dd27c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.709587097167969\n",
      "10.407631874084473\n",
      "10.127808570861816\n",
      "9.864364624023438\n",
      "9.614501953125\n",
      "9.376439094543457\n",
      "9.148944854736328\n",
      "8.931110382080078\n",
      "8.722230911254883\n",
      "8.521749496459961\n"
     ]
    }
   ],
   "source": [
    "# Set up training of the neural network\n",
    "# Learning rate eta\n",
    "eta = 0.1\n",
    "\n",
    "for _ in range(10):\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X] #(228146, 3,2)\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # Parameter update\n",
    "    for p in parameters:\n",
    "        p.data += -eta * p.grad\n",
    "\n",
    "# print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3867d158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 46329,  45448,  76040, 110853, 184071,  99147, 145450, 105784, 156240,\n",
       "         40849, 195380, 228129, 182621, 118037,  57119, 176396, 161568,  32745,\n",
       "           307,  12633,  15417,  75044, 177368, 125289, 213544, 194014,  70736,\n",
       "         84005, 212725,   5563, 118462, 100756])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The above network reduces the loss but much too slowly\n",
    "# Instead of performing forward and backward passes on the entire training set, randomly select mini-batches.\n",
    "\n",
    "# Mini-batch size = 32\n",
    "torch.randint(0, X.shape[0], (32,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "323e53c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6868302822113037\n"
     ]
    }
   ],
   "source": [
    "# Set up training of the neural network\n",
    "# Learning rate eta\n",
    "eta = 0.1\n",
    "\n",
    "for _ in range(1000):\n",
    "    \n",
    "    # Construct minibatch\n",
    "    idx = torch.randint(0, X.shape[0], (32,))\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X[idx]] #(32, 3,2)\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[idx])\n",
    "    #print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # Parameter update\n",
    "    for p in parameters:\n",
    "        p.data += -eta * p.grad\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2bc6e1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.628147602081299\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss for the entire dataset\n",
    "emb = C[X] #(32, 3,2)\n",
    "h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b211fc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011,\n",
       "        0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011,\n",
       "        0.0011, 0.0011, 0.0011, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012,\n",
       "        0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0013, 0.0013, 0.0013,\n",
       "        0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0014,\n",
       "        0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014,\n",
       "        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n",
       "        0.0015, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016,\n",
       "        0.0016, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017,\n",
       "        0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0019,\n",
       "        0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0020, 0.0020,\n",
       "        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0021, 0.0021, 0.0021, 0.0021,\n",
       "        0.0021, 0.0021, 0.0021, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022,\n",
       "        0.0022, 0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0024, 0.0024,\n",
       "        0.0024, 0.0024, 0.0024, 0.0024, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
       "        0.0025, 0.0026, 0.0026, 0.0026, 0.0026, 0.0026, 0.0027, 0.0027, 0.0027,\n",
       "        0.0027, 0.0027, 0.0027, 0.0028, 0.0028, 0.0028, 0.0028, 0.0028, 0.0029,\n",
       "        0.0029, 0.0029, 0.0029, 0.0029, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
       "        0.0031, 0.0031, 0.0031, 0.0031, 0.0032, 0.0032, 0.0032, 0.0032, 0.0032,\n",
       "        0.0033, 0.0033, 0.0033, 0.0033, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034,\n",
       "        0.0035, 0.0035, 0.0035, 0.0035, 0.0036, 0.0036, 0.0036, 0.0036, 0.0037,\n",
       "        0.0037, 0.0037, 0.0037, 0.0038, 0.0038, 0.0038, 0.0039, 0.0039, 0.0039,\n",
       "        0.0039, 0.0040, 0.0040, 0.0040, 0.0040, 0.0041, 0.0041, 0.0041, 0.0042,\n",
       "        0.0042, 0.0042, 0.0042, 0.0043, 0.0043, 0.0043, 0.0044, 0.0044, 0.0044,\n",
       "        0.0045, 0.0045, 0.0045, 0.0045, 0.0046, 0.0046, 0.0046, 0.0047, 0.0047,\n",
       "        0.0047, 0.0048, 0.0048, 0.0048, 0.0049, 0.0049, 0.0049, 0.0050, 0.0050,\n",
       "        0.0050, 0.0051, 0.0051, 0.0051, 0.0052, 0.0052, 0.0053, 0.0053, 0.0053,\n",
       "        0.0054, 0.0054, 0.0054, 0.0055, 0.0055, 0.0056, 0.0056, 0.0056, 0.0057,\n",
       "        0.0057, 0.0058, 0.0058, 0.0058, 0.0059, 0.0059, 0.0060, 0.0060, 0.0060,\n",
       "        0.0061, 0.0061, 0.0062, 0.0062, 0.0062, 0.0063, 0.0063, 0.0064, 0.0064,\n",
       "        0.0065, 0.0065, 0.0066, 0.0066, 0.0067, 0.0067, 0.0067, 0.0068, 0.0068,\n",
       "        0.0069, 0.0069, 0.0070, 0.0070, 0.0071, 0.0071, 0.0072, 0.0072, 0.0073,\n",
       "        0.0073, 0.0074, 0.0074, 0.0075, 0.0075, 0.0076, 0.0076, 0.0077, 0.0077,\n",
       "        0.0078, 0.0079, 0.0079, 0.0080, 0.0080, 0.0081, 0.0081, 0.0082, 0.0082,\n",
       "        0.0083, 0.0084, 0.0084, 0.0085, 0.0085, 0.0086, 0.0086, 0.0087, 0.0088,\n",
       "        0.0088, 0.0089, 0.0090, 0.0090, 0.0091, 0.0091, 0.0092, 0.0093, 0.0093,\n",
       "        0.0094, 0.0095, 0.0095, 0.0096, 0.0097, 0.0097, 0.0098, 0.0099, 0.0099,\n",
       "        0.0100, 0.0101, 0.0101, 0.0102, 0.0103, 0.0104, 0.0104, 0.0105, 0.0106,\n",
       "        0.0106, 0.0107, 0.0108, 0.0109, 0.0109, 0.0110, 0.0111, 0.0112, 0.0112,\n",
       "        0.0113, 0.0114, 0.0115, 0.0116, 0.0116, 0.0117, 0.0118, 0.0119, 0.0120,\n",
       "        0.0121, 0.0121, 0.0122, 0.0123, 0.0124, 0.0125, 0.0126, 0.0127, 0.0127,\n",
       "        0.0128, 0.0129, 0.0130, 0.0131, 0.0132, 0.0133, 0.0134, 0.0135, 0.0136,\n",
       "        0.0137, 0.0137, 0.0138, 0.0139, 0.0140, 0.0141, 0.0142, 0.0143, 0.0144,\n",
       "        0.0145, 0.0146, 0.0147, 0.0148, 0.0149, 0.0150, 0.0151, 0.0152, 0.0154,\n",
       "        0.0155, 0.0156, 0.0157, 0.0158, 0.0159, 0.0160, 0.0161, 0.0162, 0.0163,\n",
       "        0.0165, 0.0166, 0.0167, 0.0168, 0.0169, 0.0170, 0.0171, 0.0173, 0.0174,\n",
       "        0.0175, 0.0176, 0.0178, 0.0179, 0.0180, 0.0181, 0.0182, 0.0184, 0.0185,\n",
       "        0.0186, 0.0188, 0.0189, 0.0190, 0.0192, 0.0193, 0.0194, 0.0196, 0.0197,\n",
       "        0.0198, 0.0200, 0.0201, 0.0202, 0.0204, 0.0205, 0.0207, 0.0208, 0.0210,\n",
       "        0.0211, 0.0212, 0.0214, 0.0215, 0.0217, 0.0218, 0.0220, 0.0221, 0.0223,\n",
       "        0.0225, 0.0226, 0.0228, 0.0229, 0.0231, 0.0232, 0.0234, 0.0236, 0.0237,\n",
       "        0.0239, 0.0241, 0.0242, 0.0244, 0.0246, 0.0247, 0.0249, 0.0251, 0.0253,\n",
       "        0.0254, 0.0256, 0.0258, 0.0260, 0.0261, 0.0263, 0.0265, 0.0267, 0.0269,\n",
       "        0.0271, 0.0273, 0.0274, 0.0276, 0.0278, 0.0280, 0.0282, 0.0284, 0.0286,\n",
       "        0.0288, 0.0290, 0.0292, 0.0294, 0.0296, 0.0298, 0.0300, 0.0302, 0.0304,\n",
       "        0.0307, 0.0309, 0.0311, 0.0313, 0.0315, 0.0317, 0.0320, 0.0322, 0.0324,\n",
       "        0.0326, 0.0328, 0.0331, 0.0333, 0.0335, 0.0338, 0.0340, 0.0342, 0.0345,\n",
       "        0.0347, 0.0350, 0.0352, 0.0354, 0.0357, 0.0359, 0.0362, 0.0364, 0.0367,\n",
       "        0.0369, 0.0372, 0.0375, 0.0377, 0.0380, 0.0382, 0.0385, 0.0388, 0.0390,\n",
       "        0.0393, 0.0396, 0.0399, 0.0401, 0.0404, 0.0407, 0.0410, 0.0413, 0.0416,\n",
       "        0.0418, 0.0421, 0.0424, 0.0427, 0.0430, 0.0433, 0.0436, 0.0439, 0.0442,\n",
       "        0.0445, 0.0448, 0.0451, 0.0455, 0.0458, 0.0461, 0.0464, 0.0467, 0.0471,\n",
       "        0.0474, 0.0477, 0.0480, 0.0484, 0.0487, 0.0491, 0.0494, 0.0497, 0.0501,\n",
       "        0.0504, 0.0508, 0.0511, 0.0515, 0.0518, 0.0522, 0.0526, 0.0529, 0.0533,\n",
       "        0.0537, 0.0540, 0.0544, 0.0548, 0.0552, 0.0556, 0.0559, 0.0563, 0.0567,\n",
       "        0.0571, 0.0575, 0.0579, 0.0583, 0.0587, 0.0591, 0.0595, 0.0599, 0.0604,\n",
       "        0.0608, 0.0612, 0.0616, 0.0621, 0.0625, 0.0629, 0.0634, 0.0638, 0.0642,\n",
       "        0.0647, 0.0651, 0.0656, 0.0660, 0.0665, 0.0670, 0.0674, 0.0679, 0.0684,\n",
       "        0.0688, 0.0693, 0.0698, 0.0703, 0.0708, 0.0713, 0.0718, 0.0723, 0.0728,\n",
       "        0.0733, 0.0738, 0.0743, 0.0748, 0.0753, 0.0758, 0.0764, 0.0769, 0.0774,\n",
       "        0.0780, 0.0785, 0.0790, 0.0796, 0.0802, 0.0807, 0.0813, 0.0818, 0.0824,\n",
       "        0.0830, 0.0835, 0.0841, 0.0847, 0.0853, 0.0859, 0.0865, 0.0871, 0.0877,\n",
       "        0.0883, 0.0889, 0.0895, 0.0901, 0.0908, 0.0914, 0.0920, 0.0927, 0.0933,\n",
       "        0.0940, 0.0946, 0.0953, 0.0959, 0.0966, 0.0973, 0.0979, 0.0986, 0.0993,\n",
       "        0.1000, 0.1007, 0.1014, 0.1021, 0.1028, 0.1035, 0.1042, 0.1050, 0.1057,\n",
       "        0.1064, 0.1072, 0.1079, 0.1087, 0.1094, 0.1102, 0.1109, 0.1117, 0.1125,\n",
       "        0.1133, 0.1140, 0.1148, 0.1156, 0.1164, 0.1172, 0.1181, 0.1189, 0.1197,\n",
       "        0.1205, 0.1214, 0.1222, 0.1231, 0.1239, 0.1248, 0.1256, 0.1265, 0.1274,\n",
       "        0.1283, 0.1292, 0.1301, 0.1310, 0.1319, 0.1328, 0.1337, 0.1346, 0.1356,\n",
       "        0.1365, 0.1374, 0.1384, 0.1394, 0.1403, 0.1413, 0.1423, 0.1433, 0.1443,\n",
       "        0.1453, 0.1463, 0.1473, 0.1483, 0.1493, 0.1504, 0.1514, 0.1525, 0.1535,\n",
       "        0.1546, 0.1557, 0.1567, 0.1578, 0.1589, 0.1600, 0.1611, 0.1623, 0.1634,\n",
       "        0.1645, 0.1657, 0.1668, 0.1680, 0.1691, 0.1703, 0.1715, 0.1727, 0.1739,\n",
       "        0.1751, 0.1763, 0.1775, 0.1788, 0.1800, 0.1812, 0.1825, 0.1838, 0.1850,\n",
       "        0.1863, 0.1876, 0.1889, 0.1902, 0.1916, 0.1929, 0.1942, 0.1956, 0.1969,\n",
       "        0.1983, 0.1997, 0.2010, 0.2024, 0.2038, 0.2053, 0.2067, 0.2081, 0.2096,\n",
       "        0.2110, 0.2125, 0.2140, 0.2154, 0.2169, 0.2184, 0.2200, 0.2215, 0.2230,\n",
       "        0.2246, 0.2261, 0.2277, 0.2293, 0.2309, 0.2325, 0.2341, 0.2357, 0.2373,\n",
       "        0.2390, 0.2406, 0.2423, 0.2440, 0.2457, 0.2474, 0.2491, 0.2508, 0.2526,\n",
       "        0.2543, 0.2561, 0.2579, 0.2597, 0.2615, 0.2633, 0.2651, 0.2669, 0.2688,\n",
       "        0.2707, 0.2725, 0.2744, 0.2763, 0.2783, 0.2802, 0.2821, 0.2841, 0.2861,\n",
       "        0.2880, 0.2900, 0.2921, 0.2941, 0.2961, 0.2982, 0.3002, 0.3023, 0.3044,\n",
       "        0.3065, 0.3087, 0.3108, 0.3130, 0.3151, 0.3173, 0.3195, 0.3217, 0.3240,\n",
       "        0.3262, 0.3285, 0.3308, 0.3331, 0.3354, 0.3377, 0.3400, 0.3424, 0.3448,\n",
       "        0.3472, 0.3496, 0.3520, 0.3544, 0.3569, 0.3594, 0.3619, 0.3644, 0.3669,\n",
       "        0.3695, 0.3720, 0.3746, 0.3772, 0.3798, 0.3825, 0.3851, 0.3878, 0.3905,\n",
       "        0.3932, 0.3959, 0.3987, 0.4014, 0.4042, 0.4070, 0.4098, 0.4127, 0.4155,\n",
       "        0.4184, 0.4213, 0.4243, 0.4272, 0.4302, 0.4331, 0.4362, 0.4392, 0.4422,\n",
       "        0.4453, 0.4484, 0.4515, 0.4546, 0.4578, 0.4610, 0.4642, 0.4674, 0.4706,\n",
       "        0.4739, 0.4772, 0.4805, 0.4838, 0.4872, 0.4906, 0.4940, 0.4974, 0.5008,\n",
       "        0.5043, 0.5078, 0.5113, 0.5149, 0.5185, 0.5221, 0.5257, 0.5293, 0.5330,\n",
       "        0.5367, 0.5404, 0.5442, 0.5479, 0.5517, 0.5556, 0.5594, 0.5633, 0.5672,\n",
       "        0.5712, 0.5751, 0.5791, 0.5831, 0.5872, 0.5913, 0.5954, 0.5995, 0.6036,\n",
       "        0.6078, 0.6120, 0.6163, 0.6206, 0.6249, 0.6292, 0.6336, 0.6380, 0.6424,\n",
       "        0.6469, 0.6513, 0.6559, 0.6604, 0.6650, 0.6696, 0.6743, 0.6789, 0.6837,\n",
       "        0.6884, 0.6932, 0.6980, 0.7028, 0.7077, 0.7126, 0.7176, 0.7225, 0.7275,\n",
       "        0.7326, 0.7377, 0.7428, 0.7480, 0.7531, 0.7584, 0.7636, 0.7689, 0.7743,\n",
       "        0.7796, 0.7850, 0.7905, 0.7960, 0.8015, 0.8071, 0.8127, 0.8183, 0.8240,\n",
       "        0.8297, 0.8355, 0.8412, 0.8471, 0.8530, 0.8589, 0.8648, 0.8708, 0.8769,\n",
       "        0.8830, 0.8891, 0.8953, 0.9015, 0.9077, 0.9140, 0.9204, 0.9268, 0.9332,\n",
       "        0.9397, 0.9462, 0.9528, 0.9594, 0.9660, 0.9727, 0.9795, 0.9863, 0.9931,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experimenting with the learning rate\n",
    "# Change the learning rate from 0.001 to 1 during training\n",
    "\n",
    "lre = torch.linspace(-3, 0, 1000)\n",
    "lrs = 10**lre\n",
    "lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78ccbcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.376246452331543\n"
     ]
    }
   ],
   "source": [
    "# Set up training of the neural network\n",
    "lri = []\n",
    "lossi = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    # Construct minibatch\n",
    "    idx = torch.randint(0, X.shape[0], (32,))\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X[idx]] #(32, 3,2)\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[idx])\n",
    "    # print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # Parameter update\n",
    "    lr = lrs[i]\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    # Track stats\n",
    "    lri.append(lre[i])\n",
    "    lossi.append(loss.item())\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "85855377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fec6468d1b0>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lri,lossi)\n",
    "\n",
    "# The chart below shows that the learning rate exponent of about -1.0 is pretty good\n",
    "# This gives the ideal learning rate as 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "99a78d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the full data set and optimize the neural network\n",
    "\n",
    "# Build the dataset\n",
    "\n",
    "block_size = 3     # Context Length: How many previous characters do we use to predict the next one?\n",
    "X, Y = [], []\n",
    "for w in words:\n",
    "    # print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        idx = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(idx)\n",
    "        # print(''.join(itos[i] for i in context), '----->', itos[idx])\n",
    "        context = context[1:] + [idx]     # Crop and append\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "93c4421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27,2), generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100,27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "66d6cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cb3973b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.39837384223938\n"
     ]
    }
   ],
   "source": [
    "# Set up training of the neural network\n",
    "eta = 0.1\n",
    "\n",
    "for i in range(10000):\n",
    "    \n",
    "    # Construct minibatch\n",
    "    idx = torch.randint(0, X.shape[0], (32,))\n",
    "\n",
    "    # Forward pass\n",
    "    emb = C[X[idx]] #(32, 3,2)\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[idx])\n",
    "    # print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # Parameter update\n",
    "    for p in parameters:\n",
    "        p.data += -eta * p.grad\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "948dde1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2873759269714355\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss for the entire dataset\n",
    "emb = C[X] #(32, 3,2)\n",
    "h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e3fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that 2.28 is better than the loss on the bigram model that we achieved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
